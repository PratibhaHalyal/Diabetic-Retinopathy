{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d38f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "# from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import time\n",
    "from tensorflow.keras import Model,layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import  CSVLogger\n",
    "from tensorflow.keras.constraints import UnitNorm\n",
    "IMAGE_SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3553798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 11 10:56:09 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    41W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    44W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f89160bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0:2], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        tf.config.experimental.set_memory_growth(gpus[1], True)\n",
    "        #tf.config.experimental.set_memory_growth(gpus[2], True)\n",
    "        #tf.config.experimental.set_memory_growth(gpus[3], True)\n",
    "        #tf.config.experimental.set_memory_growth(gpus[4], True)\n",
    "        #tf.config.experimental.set_memory_growth(gpus[5], True)\n",
    "        #tf.config.experimental.set_memory_growth(gpus[6], True)\n",
    "        #tf.config.experimental.set_memory_growth(gpus[7], True)\n",
    "\n",
    "        #tf.config.experimental.set_virtual_device_configuration(gpus[3], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=26000)])\n",
    "\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "#tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10000)])\n",
    "\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#tf.config.gpu.set_per_process_memory_fraction(0.75)\n",
    "#tf.config.gpu.set_per_process_memory_growth(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a17b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = '/workspace/msp/Retinopathy_dataset/train_vinayak/Opencv_augmented_modified'\n",
    "# valid_path = '/workspace/msp/Retinopathy_dataset/train_vinayak/Opencv_modified_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac24072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='/workspace/DP/Tensorflow/tf_comp_dp/Opencv_augmented_modified'\n",
    "test_path='/workspace/DP/Tensorflow/tf_comp_dp/Opencv_modified_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7d67105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf4fa513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16656 files belonging to 5 classes.\n",
      "Using 13325 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds= tf.keras.utils.image_dataset_from_directory(\n",
    "          train_path,\n",
    "          validation_split=0.2,\n",
    "          subset=\"training\",\n",
    "          seed=123,\n",
    "          image_size=(224, 224),\n",
    "          batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fa0c781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1858 files belonging to 5 classes.\n",
      "Using 371 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(224, 224),\n",
    "  batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23108548",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f79d2c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5461847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "#def cohen_kappa_integerized(y_true, y_pred, num_classes=5, weights=None, metrics_collections=None, updates_collections=None, name=None):\n",
    "#    kappa, update_op = tensorflow.contrib.metrics.cohen_kappa(\n",
    "#        y_true, \n",
    "#        clip(rint(y_pred), 0, 4), \n",
    "#        num_classes, \n",
    "#        weights, \n",
    "#        metrics_collections, \n",
    "#        updates_collections, \n",
    "#        name\n",
    "#     )\n",
    "#    K.get_session().run(tensorflow.local_variables_initializer())\n",
    "#    with tensorflow.control_dependencies([update_op]):\n",
    "#        kappa = tensorflow.identity(kappa)\n",
    "#    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6042ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2302028",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "       def createModel2(baseModelTrainable):\n",
    "        image_inputShape = (224, 224, 3)\n",
    "#         base_model = DenseNet121(\n",
    "#                     include_top=False, weights='imagenet',\n",
    "#                     input_shape=image_inputShape, pooling=None\n",
    "#                 )\n",
    "        base_model=ResNet50(input_shape=IMAGE_SIZE + [3],weights=\"imagenet\", include_top=False , pooling=None)\n",
    "        base_model.trainable = baseModelTrainable\n",
    "        avgPool_layer = tf.keras.layers.GlobalAveragePooling2D() (base_model.output)\n",
    "        dropOut0 = tf.keras.layers.Dropout(0.5)(avgPool_layer )\n",
    "        fullLayer1 = tf.keras.layers.Dense(1250,  name='fullLayer1' ) ( dropOut0)\n",
    "        prelu1 = tf.keras.layers.PReLU(name='pRelu1') (fullLayer1)\n",
    "        dropOut1 = tf.keras.layers.Dropout(0.5)(prelu1 )\n",
    "        fullLayer2 = tf.keras.layers.Dense(512,  name='fullLayer2') (dropOut1)\n",
    "        prelu2 = tf.keras.layers.PReLU( name='pRelu2') (fullLayer2 )\n",
    "        dropOut2 = tf.keras.layers.Dropout(0.2)(prelu2 )\n",
    "        out = tf.keras.layers.Dense(5,  name='fullLayer3') (dropOut2 )\n",
    "\n",
    "        model=models.Model(inputs=base_model.input, outputs=out)\n",
    "\n",
    "        model.get_layer('pRelu1').set_weights([np.ones(1250)*0.25])\n",
    "        model.get_layer('pRelu2').set_weights([np.ones(512)*0.25])\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd5c1bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFilePath= '/workspace/DP/Tensorflow/Results/2_gpu_DP.csv'\n",
    "csv_logger = CSVLogger(csvFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e45bc154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as tk\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46c385cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_addons.metrics.cohens_kappa.CohenKappa at 0x7fd654b76760>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfa.metrics.CohenKappa(\n",
    "    num_classes = 5,\n",
    "    name = 'cohen_kappa',\n",
    "    weightage =None,\n",
    "    sparse_labels = False,\n",
    "    regression = False,\n",
    "    dtype = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f21d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afa8f697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 2048)         0           ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " fullLayer1 (Dense)             (None, 1250)         2561250     ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " pRelu1 (PReLU)                 (None, 1250)         1250        ['fullLayer1[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 1250)         0           ['pRelu1[0][0]']                 \n",
      "                                                                                                  \n",
      " fullLayer2 (Dense)             (None, 512)          640512      ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " pRelu2 (PReLU)                 (None, 512)          512         ['fullLayer2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 512)          0           ['pRelu2[0][0]']                 \n",
      "                                                                                                  \n",
      " fullLayer3 (Dense)             (None, 5)            2565        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,793,801\n",
      "Trainable params: 26,740,681\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = createModel2(True)\n",
    "    opt = RMSprop()\n",
    "    def get_lr_metric(optimizer):\n",
    "        def lr(y_true, y_pred):\n",
    "             return optimizer.lr\n",
    "        return lr\n",
    "\n",
    "    lr_track = get_lr_metric(opt)\n",
    "\n",
    "    model.compile(optimizer = opt, \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy',precision_m,f1_m,tfa.metrics.CohenKappa(num_classes=5, sparse_labels=True)])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e2fb964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 2048)         0           ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " fullLayer1 (Dense)             (None, 1250)         2561250     ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " pRelu1 (PReLU)                 (None, 1250)         1250        ['fullLayer1[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 1250)         0           ['pRelu1[0][0]']                 \n",
      "                                                                                                  \n",
      " fullLayer2 (Dense)             (None, 512)          640512      ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " pRelu2 (PReLU)                 (None, 512)          512         ['fullLayer2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 512)          0           ['pRelu2[0][0]']                 \n",
      "                                                                                                  \n",
      " fullLayer3 (Dense)             (None, 5)            2565        ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,793,801\n",
      "Trainable params: 26,740,681\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = createModel2(True)\n",
    "#     opti = tf.keras.optimizers.SGD(\n",
    "#         learning_rate=0.01, momentum=0.9, nesterov=True, name='SGD')\n",
    "    opti = tf.keras.optimizers.Adagrad(\n",
    "    learning_rate=0.001,\n",
    "    initial_accumulator_value=0.01,\n",
    "    epsilon=1e-06,\n",
    "    name=\"Adagrad\"\n",
    "    )\n",
    "    model.compile(optimizer = opti, \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy',precision_m,f1_m,tfa.metrics.CohenKappa(num_classes=5, sparse_labels=True)])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a4e213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(tensorflow.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        #self.times.append(time.time() - self.epoch_time_start)\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "        print(end='\\t')\n",
    "        print(\"Total epoch training time = \",self.times)\n",
    "        \n",
    "#     def on_batch_begin(self, batch, logs=None):\n",
    "#         self.batch_time_start = time.time()\n",
    "\n",
    "#     def on_batch_end(self, batch, logs=None):\n",
    "#         self.batch_time_end.append(time.time() - self.batch_time_start)\n",
    "#         print(\"Total batch training time = \",self.batch_time_end)    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa2a0338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 11:05:39.791573: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 13325\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025TensorSliceDataset:16\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 220 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 220 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 11:06:04.616117: I tensorflow/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-11 11:06:04.712184: I tensorflow/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833/833 [==============================] - ETA: 0s - loss: 1.1050 - accuracy: 0.5465 - precision_m: 0.9348 - f1_m: 1.3604 - cohen_kappa: 0.4318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 11:06:59.248172: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 371\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025TensorSliceDataset:23\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTotal epoch training time =  [85.15624141693115]\n",
      "833/833 [==============================] - 85s 69ms/step - loss: 1.1050 - accuracy: 0.5465 - precision_m: 0.9348 - f1_m: 1.3604 - cohen_kappa: 0.4318 - val_loss: 0.8038 - val_accuracy: 0.6658 - val_precision_m: 0.8629 - val_f1_m: 1.2621 - val_cohen_kappa: 0.5730\n",
      "Epoch 2/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.7713 - accuracy: 0.6916 - precision_m: 0.9006 - f1_m: 1.3338 - cohen_kappa: 0.6137\tTotal epoch training time =  [85.15624141693115, 47.82199311256409]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.7713 - accuracy: 0.6916 - precision_m: 0.9006 - f1_m: 1.3338 - cohen_kappa: 0.6137 - val_loss: 0.6172 - val_accuracy: 0.7466 - val_precision_m: 0.8312 - val_f1_m: 1.2474 - val_cohen_kappa: 0.6780\n",
      "Epoch 3/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.5567 - accuracy: 0.7843 - precision_m: 0.8924 - f1_m: 1.3182 - cohen_kappa: 0.7299\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802]\n",
      "833/833 [==============================] - 48s 58ms/step - loss: 0.5569 - accuracy: 0.7842 - precision_m: 0.8923 - f1_m: 1.3181 - cohen_kappa: 0.7299 - val_loss: 0.5619 - val_accuracy: 0.7790 - val_precision_m: 0.8405 - val_f1_m: 1.2471 - val_cohen_kappa: 0.7200\n",
      "Epoch 4/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.3520 - accuracy: 0.8695 - precision_m: 0.8763 - f1_m: 1.2856 - cohen_kappa: 0.8366\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225]\n",
      "833/833 [==============================] - 48s 58ms/step - loss: 0.3520 - accuracy: 0.8695 - precision_m: 0.8763 - f1_m: 1.2856 - cohen_kappa: 0.8366 - val_loss: 0.5015 - val_accuracy: 0.8167 - val_precision_m: 0.8033 - val_f1_m: 1.1988 - val_cohen_kappa: 0.7670\n",
      "Epoch 5/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.9202 - precision_m: 0.8667 - f1_m: 1.2607 - cohen_kappa: 0.9002\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535]\n",
      "833/833 [==============================] - 48s 58ms/step - loss: 0.2178 - accuracy: 0.9202 - precision_m: 0.8667 - f1_m: 1.2607 - cohen_kappa: 0.9002 - val_loss: 0.6779 - val_accuracy: 0.8005 - val_precision_m: 0.7738 - val_f1_m: 1.1337 - val_cohen_kappa: 0.7460\n",
      "Epoch 6/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9486 - precision_m: 0.8603 - f1_m: 1.2417 - cohen_kappa: 0.9357\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124]\n",
      "833/833 [==============================] - 48s 58ms/step - loss: 0.1485 - accuracy: 0.9486 - precision_m: 0.8603 - f1_m: 1.2417 - cohen_kappa: 0.9357 - val_loss: 0.4950 - val_accuracy: 0.8464 - val_precision_m: 0.8091 - val_f1_m: 1.1857 - val_cohen_kappa: 0.8037\n",
      "Epoch 7/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.1043 - accuracy: 0.9633 - precision_m: 0.8523 - f1_m: 1.2219 - cohen_kappa: 0.9540\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219]\n",
      "833/833 [==============================] - 49s 59ms/step - loss: 0.1043 - accuracy: 0.9632 - precision_m: 0.8525 - f1_m: 1.2221 - cohen_kappa: 0.9540 - val_loss: 0.5020 - val_accuracy: 0.8491 - val_precision_m: 0.7944 - val_f1_m: 1.1513 - val_cohen_kappa: 0.8077\n",
      "Epoch 8/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9740 - precision_m: 0.8519 - f1_m: 1.2120 - cohen_kappa: 0.9675\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0771 - accuracy: 0.9740 - precision_m: 0.8519 - f1_m: 1.2120 - cohen_kappa: 0.9675 - val_loss: 0.5210 - val_accuracy: 0.8437 - val_precision_m: 0.7768 - val_f1_m: 1.1209 - val_cohen_kappa: 0.8002\n",
      "Epoch 9/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9802 - precision_m: 0.8474 - f1_m: 1.2006 - cohen_kappa: 0.9752\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0604 - accuracy: 0.9802 - precision_m: 0.8474 - f1_m: 1.2006 - cohen_kappa: 0.9752 - val_loss: 0.5188 - val_accuracy: 0.8464 - val_precision_m: 0.8191 - val_f1_m: 1.1796 - val_cohen_kappa: 0.8042\n",
      "Epoch 10/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9856 - precision_m: 0.8467 - f1_m: 1.1907 - cohen_kappa: 0.9820\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125]\n",
      "833/833 [==============================] - 49s 58ms/step - loss: 0.0444 - accuracy: 0.9856 - precision_m: 0.8467 - f1_m: 1.1907 - cohen_kappa: 0.9820 - val_loss: 0.6154 - val_accuracy: 0.8491 - val_precision_m: 0.8002 - val_f1_m: 1.1526 - val_cohen_kappa: 0.8077\n",
      "Epoch 11/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9869 - precision_m: 0.8442 - f1_m: 1.1814 - cohen_kappa: 0.9836\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594]\n",
      "833/833 [==============================] - 48s 58ms/step - loss: 0.0430 - accuracy: 0.9869 - precision_m: 0.8442 - f1_m: 1.1814 - cohen_kappa: 0.9836 - val_loss: 0.5787 - val_accuracy: 0.8518 - val_precision_m: 0.7705 - val_f1_m: 1.1096 - val_cohen_kappa: 0.8108\n",
      "Epoch 12/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9869 - precision_m: 0.8394 - f1_m: 1.1700 - cohen_kappa: 0.9837\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668]\n",
      "833/833 [==============================] - 48s 58ms/step - loss: 0.0366 - accuracy: 0.9869 - precision_m: 0.8394 - f1_m: 1.1700 - cohen_kappa: 0.9837 - val_loss: 0.4730 - val_accuracy: 0.8625 - val_precision_m: 0.7862 - val_f1_m: 1.1329 - val_cohen_kappa: 0.8245\n",
      "Epoch 13/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9891 - precision_m: 0.8354 - f1_m: 1.1650 - cohen_kappa: 0.9864\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086]\n",
      "833/833 [==============================] - 48s 58ms/step - loss: 0.0320 - accuracy: 0.9891 - precision_m: 0.8354 - f1_m: 1.1650 - cohen_kappa: 0.9864 - val_loss: 0.4815 - val_accuracy: 0.8787 - val_precision_m: 0.7710 - val_f1_m: 1.1070 - val_cohen_kappa: 0.8449\n",
      "Epoch 14/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9922 - precision_m: 0.8342 - f1_m: 1.1577 - cohen_kappa: 0.9902\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174]\n",
      "833/833 [==============================] - 49s 59ms/step - loss: 0.0240 - accuracy: 0.9922 - precision_m: 0.8342 - f1_m: 1.1577 - cohen_kappa: 0.9902 - val_loss: 0.5650 - val_accuracy: 0.8652 - val_precision_m: 0.7696 - val_f1_m: 1.1072 - val_cohen_kappa: 0.8281\n",
      "Epoch 15/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9936 - precision_m: 0.8313 - f1_m: 1.1517 - cohen_kappa: 0.9920\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174]\n",
      "833/833 [==============================] - 49s 59ms/step - loss: 0.0216 - accuracy: 0.9936 - precision_m: 0.8313 - f1_m: 1.1517 - cohen_kappa: 0.9920 - val_loss: 0.5186 - val_accuracy: 0.8760 - val_precision_m: 0.7992 - val_f1_m: 1.1336 - val_cohen_kappa: 0.8413\n",
      "Epoch 16/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9934 - precision_m: 0.8319 - f1_m: 1.1505 - cohen_kappa: 0.9917\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103]\n",
      "833/833 [==============================] - 50s 59ms/step - loss: 0.0197 - accuracy: 0.9934 - precision_m: 0.8319 - f1_m: 1.1505 - cohen_kappa: 0.9917 - val_loss: 0.4796 - val_accuracy: 0.8787 - val_precision_m: 0.7792 - val_f1_m: 1.1176 - val_cohen_kappa: 0.8447\n",
      "Epoch 17/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9947 - precision_m: 0.8318 - f1_m: 1.1458 - cohen_kappa: 0.9934\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298]\n",
      "833/833 [==============================] - 49s 59ms/step - loss: 0.0174 - accuracy: 0.9947 - precision_m: 0.8318 - f1_m: 1.1458 - cohen_kappa: 0.9934 - val_loss: 0.5144 - val_accuracy: 0.8706 - val_precision_m: 0.7825 - val_f1_m: 1.1149 - val_cohen_kappa: 0.8346\n",
      "Epoch 18/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9942 - precision_m: 0.8257 - f1_m: 1.1351 - cohen_kappa: 0.9928\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363]\n",
      "833/833 [==============================] - 49s 59ms/step - loss: 0.0176 - accuracy: 0.9942 - precision_m: 0.8257 - f1_m: 1.1351 - cohen_kappa: 0.9928 - val_loss: 0.6219 - val_accuracy: 0.8598 - val_precision_m: 0.7766 - val_f1_m: 1.1050 - val_cohen_kappa: 0.8211\n",
      "Epoch 19/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9957 - precision_m: 0.8237 - f1_m: 1.1324 - cohen_kappa: 0.9946\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0132 - accuracy: 0.9957 - precision_m: 0.8236 - f1_m: 1.1323 - cohen_kappa: 0.9946 - val_loss: 0.6107 - val_accuracy: 0.8544 - val_precision_m: 0.7725 - val_f1_m: 1.1044 - val_cohen_kappa: 0.8146\n",
      "Epoch 20/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9968 - precision_m: 0.8279 - f1_m: 1.1307 - cohen_kappa: 0.9960\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596]\n",
      "833/833 [==============================] - 49s 58ms/step - loss: 0.0125 - accuracy: 0.9968 - precision_m: 0.8279 - f1_m: 1.1307 - cohen_kappa: 0.9960 - val_loss: 0.6043 - val_accuracy: 0.8571 - val_precision_m: 0.7645 - val_f1_m: 1.0921 - val_cohen_kappa: 0.8182\n",
      "Epoch 21/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9959 - precision_m: 0.8265 - f1_m: 1.1299 - cohen_kappa: 0.9948\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525]\n",
      "833/833 [==============================] - 47s 57ms/step - loss: 0.0138 - accuracy: 0.9959 - precision_m: 0.8265 - f1_m: 1.1297 - cohen_kappa: 0.9948 - val_loss: 0.5264 - val_accuracy: 0.8760 - val_precision_m: 0.7893 - val_f1_m: 1.1176 - val_cohen_kappa: 0.8416\n",
      "Epoch 22/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9970 - precision_m: 0.8279 - f1_m: 1.1274 - cohen_kappa: 0.9962\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134]\n",
      "833/833 [==============================] - 47s 56ms/step - loss: 0.0103 - accuracy: 0.9970 - precision_m: 0.8279 - f1_m: 1.1274 - cohen_kappa: 0.9962 - val_loss: 0.6212 - val_accuracy: 0.8491 - val_precision_m: 0.7661 - val_f1_m: 1.1022 - val_cohen_kappa: 0.8078\n",
      "Epoch 23/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9981 - precision_m: 0.8240 - f1_m: 1.1196 - cohen_kappa: 0.9977\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811]\n",
      "833/833 [==============================] - 47s 57ms/step - loss: 0.0075 - accuracy: 0.9981 - precision_m: 0.8240 - f1_m: 1.1196 - cohen_kappa: 0.9977 - val_loss: 0.5457 - val_accuracy: 0.8733 - val_precision_m: 0.7496 - val_f1_m: 1.0704 - val_cohen_kappa: 0.8383\n",
      "Epoch 24/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9973 - precision_m: 0.8258 - f1_m: 1.1228 - cohen_kappa: 0.9966\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884]\n",
      "833/833 [==============================] - 48s 58ms/step - loss: 0.0088 - accuracy: 0.9973 - precision_m: 0.8253 - f1_m: 1.1223 - cohen_kappa: 0.9966 - val_loss: 0.6262 - val_accuracy: 0.8625 - val_precision_m: 0.7909 - val_f1_m: 1.1289 - val_cohen_kappa: 0.8243\n",
      "Epoch 25/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9977 - precision_m: 0.8231 - f1_m: 1.1147 - cohen_kappa: 0.9971\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0075 - accuracy: 0.9976 - precision_m: 0.8233 - f1_m: 1.1149 - cohen_kappa: 0.9970 - val_loss: 0.6683 - val_accuracy: 0.8625 - val_precision_m: 0.7480 - val_f1_m: 1.0720 - val_cohen_kappa: 0.8244\n",
      "Epoch 26/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9969 - precision_m: 0.8247 - f1_m: 1.1181 - cohen_kappa: 0.9961\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0104 - accuracy: 0.9969 - precision_m: 0.8246 - f1_m: 1.1181 - cohen_kappa: 0.9962 - val_loss: 0.6608 - val_accuracy: 0.8491 - val_precision_m: 0.7736 - val_f1_m: 1.0950 - val_cohen_kappa: 0.8079\n",
      "Epoch 27/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9985 - precision_m: 0.8280 - f1_m: 1.1201 - cohen_kappa: 0.9981\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0063 - accuracy: 0.9985 - precision_m: 0.8280 - f1_m: 1.1201 - cohen_kappa: 0.9981 - val_loss: 0.6882 - val_accuracy: 0.8410 - val_precision_m: 0.7512 - val_f1_m: 1.0745 - val_cohen_kappa: 0.7982\n",
      "Epoch 28/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9986 - precision_m: 0.8247 - f1_m: 1.1162 - cohen_kappa: 0.9983\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301]\n",
      "833/833 [==============================] - 48s 58ms/step - loss: 0.0060 - accuracy: 0.9986 - precision_m: 0.8247 - f1_m: 1.1162 - cohen_kappa: 0.9983 - val_loss: 0.6415 - val_accuracy: 0.8733 - val_precision_m: 0.7768 - val_f1_m: 1.0941 - val_cohen_kappa: 0.8384\n",
      "Epoch 29/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9990 - precision_m: 0.8226 - f1_m: 1.1114 - cohen_kappa: 0.9988\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106]\n",
      "833/833 [==============================] - 49s 58ms/step - loss: 0.0039 - accuracy: 0.9990 - precision_m: 0.8227 - f1_m: 1.1114 - cohen_kappa: 0.9988 - val_loss: 0.5250 - val_accuracy: 0.8787 - val_precision_m: 0.7441 - val_f1_m: 1.0556 - val_cohen_kappa: 0.8450\n",
      "Epoch 30/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9989 - precision_m: 0.8168 - f1_m: 1.1008 - cohen_kappa: 0.9986\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0049 - accuracy: 0.9989 - precision_m: 0.8168 - f1_m: 1.1008 - cohen_kappa: 0.9986 - val_loss: 0.6201 - val_accuracy: 0.8679 - val_precision_m: 0.7530 - val_f1_m: 1.0734 - val_cohen_kappa: 0.8316\n",
      "Epoch 31/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9987 - precision_m: 0.8190 - f1_m: 1.1039 - cohen_kappa: 0.9984\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0047 - accuracy: 0.9987 - precision_m: 0.8191 - f1_m: 1.1041 - cohen_kappa: 0.9984 - val_loss: 0.6129 - val_accuracy: 0.8598 - val_precision_m: 0.7783 - val_f1_m: 1.1016 - val_cohen_kappa: 0.8214\n",
      "Epoch 32/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980 - precision_m: 0.8140 - f1_m: 1.1016 - cohen_kappa: 0.9976\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0069 - accuracy: 0.9980 - precision_m: 0.8140 - f1_m: 1.1016 - cohen_kappa: 0.9976 - val_loss: 0.6907 - val_accuracy: 0.8571 - val_precision_m: 0.7744 - val_f1_m: 1.0966 - val_cohen_kappa: 0.8180\n",
      "Epoch 33/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9986 - precision_m: 0.8092 - f1_m: 1.0941 - cohen_kappa: 0.9983\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437]\n",
      "833/833 [==============================] - 47s 56ms/step - loss: 0.0058 - accuracy: 0.9986 - precision_m: 0.8092 - f1_m: 1.0941 - cohen_kappa: 0.9983 - val_loss: 0.6158 - val_accuracy: 0.8518 - val_precision_m: 0.7466 - val_f1_m: 1.0609 - val_cohen_kappa: 0.8110\n",
      "Epoch 34/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9983 - precision_m: 0.8107 - f1_m: 1.0950 - cohen_kappa: 0.9978\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885]\n",
      "833/833 [==============================] - 47s 57ms/step - loss: 0.0067 - accuracy: 0.9983 - precision_m: 0.8107 - f1_m: 1.0950 - cohen_kappa: 0.9978 - val_loss: 0.5811 - val_accuracy: 0.8733 - val_precision_m: 0.7696 - val_f1_m: 1.0973 - val_cohen_kappa: 0.8380\n",
      "Epoch 35/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9987 - precision_m: 0.8190 - f1_m: 1.1055 - cohen_kappa: 0.9984\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471]\n",
      "833/833 [==============================] - 48s 58ms/step - loss: 0.0053 - accuracy: 0.9987 - precision_m: 0.8190 - f1_m: 1.1055 - cohen_kappa: 0.9984 - val_loss: 0.5990 - val_accuracy: 0.8679 - val_precision_m: 0.7750 - val_f1_m: 1.1125 - val_cohen_kappa: 0.8312\n",
      "Epoch 36/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9989 - precision_m: 0.8207 - f1_m: 1.1034 - cohen_kappa: 0.9987\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0040 - accuracy: 0.9989 - precision_m: 0.8207 - f1_m: 1.1034 - cohen_kappa: 0.9987 - val_loss: 0.6410 - val_accuracy: 0.8760 - val_precision_m: 0.7563 - val_f1_m: 1.0798 - val_cohen_kappa: 0.8415\n",
      "Epoch 37/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9987 - precision_m: 0.8246 - f1_m: 1.1040 - cohen_kappa: 0.9984\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0047 - accuracy: 0.9987 - precision_m: 0.8246 - f1_m: 1.1040 - cohen_kappa: 0.9984 - val_loss: 0.6335 - val_accuracy: 0.8598 - val_precision_m: 0.7612 - val_f1_m: 1.0898 - val_cohen_kappa: 0.8208\n",
      "Epoch 38/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9981 - precision_m: 0.8229 - f1_m: 1.1048 - cohen_kappa: 0.9977\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194, 46.95496153831482]\n",
      "833/833 [==============================] - 47s 56ms/step - loss: 0.0059 - accuracy: 0.9981 - precision_m: 0.8226 - f1_m: 1.1045 - cohen_kappa: 0.9977 - val_loss: 0.6239 - val_accuracy: 0.8679 - val_precision_m: 0.7749 - val_f1_m: 1.0947 - val_cohen_kappa: 0.8316\n",
      "Epoch 39/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9983 - precision_m: 0.8184 - f1_m: 1.0968 - cohen_kappa: 0.9979\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194, 46.95496153831482, 48.474499225616455]\n",
      "833/833 [==============================] - 48s 58ms/step - loss: 0.0049 - accuracy: 0.9983 - precision_m: 0.8185 - f1_m: 1.0970 - cohen_kappa: 0.9979 - val_loss: 0.5971 - val_accuracy: 0.8706 - val_precision_m: 0.7587 - val_f1_m: 1.0858 - val_cohen_kappa: 0.8348\n",
      "Epoch 40/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9980 - precision_m: 0.8244 - f1_m: 1.1037 - cohen_kappa: 0.9975\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194, 46.95496153831482, 48.474499225616455, 48.28712606430054]\n",
      "833/833 [==============================] - 48s 58ms/step - loss: 0.0072 - accuracy: 0.9980 - precision_m: 0.8244 - f1_m: 1.1037 - cohen_kappa: 0.9975 - val_loss: 0.6505 - val_accuracy: 0.8598 - val_precision_m: 0.7518 - val_f1_m: 1.0643 - val_cohen_kappa: 0.8214\n",
      "Epoch 41/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9988 - precision_m: 0.8186 - f1_m: 1.0965 - cohen_kappa: 0.9985\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194, 46.95496153831482, 48.474499225616455, 48.28712606430054, 47.72217583656311]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0040 - accuracy: 0.9988 - precision_m: 0.8187 - f1_m: 1.0966 - cohen_kappa: 0.9985 - val_loss: 0.6937 - val_accuracy: 0.8598 - val_precision_m: 0.7551 - val_f1_m: 1.0626 - val_cohen_kappa: 0.8215\n",
      "Epoch 42/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985 - precision_m: 0.8237 - f1_m: 1.1069 - cohen_kappa: 0.9981\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194, 46.95496153831482, 48.474499225616455, 48.28712606430054, 47.72217583656311, 47.67923331260681]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0049 - accuracy: 0.9985 - precision_m: 0.8237 - f1_m: 1.1069 - cohen_kappa: 0.9981 - val_loss: 0.5998 - val_accuracy: 0.8706 - val_precision_m: 0.7798 - val_f1_m: 1.0948 - val_cohen_kappa: 0.8346\n",
      "Epoch 43/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995 - precision_m: 0.8224 - f1_m: 1.0984 - cohen_kappa: 0.9993\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194, 46.95496153831482, 48.474499225616455, 48.28712606430054, 47.72217583656311, 47.67923331260681, 47.31889891624451]\n",
      "833/833 [==============================] - 47s 57ms/step - loss: 0.0029 - accuracy: 0.9995 - precision_m: 0.8224 - f1_m: 1.0984 - cohen_kappa: 0.9993 - val_loss: 0.6897 - val_accuracy: 0.8679 - val_precision_m: 0.7811 - val_f1_m: 1.1067 - val_cohen_kappa: 0.8316\n",
      "Epoch 44/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9986 - precision_m: 0.8203 - f1_m: 1.0946 - cohen_kappa: 0.9982\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194, 46.95496153831482, 48.474499225616455, 48.28712606430054, 47.72217583656311, 47.67923331260681, 47.31889891624451, 47.632752656936646]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0039 - accuracy: 0.9986 - precision_m: 0.8204 - f1_m: 1.0946 - cohen_kappa: 0.9982 - val_loss: 0.5803 - val_accuracy: 0.8814 - val_precision_m: 0.7657 - val_f1_m: 1.0973 - val_cohen_kappa: 0.8483\n",
      "Epoch 45/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9988 - precision_m: 0.8163 - f1_m: 1.0913 - cohen_kappa: 0.9985\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194, 46.95496153831482, 48.474499225616455, 48.28712606430054, 47.72217583656311, 47.67923331260681, 47.31889891624451, 47.632752656936646, 47.13908529281616]\n",
      "833/833 [==============================] - 47s 57ms/step - loss: 0.0033 - accuracy: 0.9988 - precision_m: 0.8163 - f1_m: 1.0913 - cohen_kappa: 0.9985 - val_loss: 0.5951 - val_accuracy: 0.8841 - val_precision_m: 0.7652 - val_f1_m: 1.0881 - val_cohen_kappa: 0.8518\n",
      "Epoch 46/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992 - precision_m: 0.8158 - f1_m: 1.0892 - cohen_kappa: 0.9991\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194, 46.95496153831482, 48.474499225616455, 48.28712606430054, 47.72217583656311, 47.67923331260681, 47.31889891624451, 47.632752656936646, 47.13908529281616, 47.408756732940674]\n",
      "833/833 [==============================] - 47s 57ms/step - loss: 0.0028 - accuracy: 0.9992 - precision_m: 0.8158 - f1_m: 1.0892 - cohen_kappa: 0.9991 - val_loss: 0.6124 - val_accuracy: 0.8760 - val_precision_m: 0.7585 - val_f1_m: 1.0828 - val_cohen_kappa: 0.8413\n",
      "Epoch 47/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991 - precision_m: 0.8173 - f1_m: 1.0894 - cohen_kappa: 0.9989\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194, 46.95496153831482, 48.474499225616455, 48.28712606430054, 47.72217583656311, 47.67923331260681, 47.31889891624451, 47.632752656936646, 47.13908529281616, 47.408756732940674, 47.397562742233276]\n",
      "833/833 [==============================] - 47s 57ms/step - loss: 0.0025 - accuracy: 0.9991 - precision_m: 0.8173 - f1_m: 1.0894 - cohen_kappa: 0.9989 - val_loss: 0.6236 - val_accuracy: 0.8814 - val_precision_m: 0.7674 - val_f1_m: 1.0982 - val_cohen_kappa: 0.8486\n",
      "Epoch 48/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9986 - precision_m: 0.8237 - f1_m: 1.0968 - cohen_kappa: 0.9983\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194, 46.95496153831482, 48.474499225616455, 48.28712606430054, 47.72217583656311, 47.67923331260681, 47.31889891624451, 47.632752656936646, 47.13908529281616, 47.408756732940674, 47.397562742233276, 47.22643971443176]\n",
      "833/833 [==============================] - 47s 57ms/step - loss: 0.0044 - accuracy: 0.9986 - precision_m: 0.8237 - f1_m: 1.0968 - cohen_kappa: 0.9983 - val_loss: 0.6237 - val_accuracy: 0.8787 - val_precision_m: 0.7526 - val_f1_m: 1.0738 - val_cohen_kappa: 0.8448\n",
      "Epoch 49/50\n",
      "832/833 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9997 - precision_m: 0.8229 - f1_m: 1.0948 - cohen_kappa: 0.9996\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194, 46.95496153831482, 48.474499225616455, 48.28712606430054, 47.72217583656311, 47.67923331260681, 47.31889891624451, 47.632752656936646, 47.13908529281616, 47.408756732940674, 47.397562742233276, 47.22643971443176, 47.77526617050171]\n",
      "833/833 [==============================] - 48s 57ms/step - loss: 0.0022 - accuracy: 0.9997 - precision_m: 0.8231 - f1_m: 1.0950 - cohen_kappa: 0.9996 - val_loss: 0.6116 - val_accuracy: 0.8679 - val_precision_m: 0.7698 - val_f1_m: 1.0921 - val_cohen_kappa: 0.8312\n",
      "Epoch 50/50\n",
      "833/833 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992 - precision_m: 0.8249 - f1_m: 1.0988 - cohen_kappa: 0.9991\tTotal epoch training time =  [85.15624141693115, 47.82199311256409, 48.1642906665802, 48.335877895355225, 48.256279945373535, 48.47376012802124, 48.87684369087219, 47.73460626602173, 47.683268785476685, 48.604278564453125, 48.06965374946594, 48.20612907409668, 48.40383529663086, 49.16398334503174, 49.28898334503174, 49.5431113243103, 49.44243097305298, 49.47183680534363, 47.68962645530701, 48.516952991485596, 47.42323660850525, 47.089887857437134, 47.32544732093811, 48.335432291030884, 47.6059091091156, 47.695870876312256, 47.70792055130005, 47.99911689758301, 48.607505083084106, 47.82686734199524, 47.58708667755127, 47.805903911590576, 46.90820574760437, 47.4580500125885, 48.49890351295471, 47.586302280426025, 47.60610604286194, 46.95496153831482, 48.474499225616455, 48.28712606430054, 47.72217583656311, 47.67923331260681, 47.31889891624451, 47.632752656936646, 47.13908529281616, 47.408756732940674, 47.397562742233276, 47.22643971443176, 47.77526617050171, 47.38142371177673]\n",
      "833/833 [==============================] - 47s 57ms/step - loss: 0.0028 - accuracy: 0.9992 - precision_m: 0.8249 - f1_m: 1.0988 - cohen_kappa: 0.9991 - val_loss: 0.6338 - val_accuracy: 0.8625 - val_precision_m: 0.7751 - val_f1_m: 1.1067 - val_cohen_kappa: 0.8248\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    epochs=50\n",
    "    time_callback = TimeHistory()\n",
    "    #model = createModel2(False)\n",
    "    try:\n",
    "        history = model.fit(\n",
    "                            train_ds,\n",
    "                            validation_data=val_ds, #steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                            epochs=epochs,\n",
    "                            callbacks=[csv_logger,time_callback]\n",
    "                           )\n",
    "        times = time_callback.times\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3b69f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dc16b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/workspace/DP/Tensorflow/Saved_models/DR_model2.h5')\n",
    "# tf.keras.models.save_model(\n",
    "#     '/workspace/DP/Tensorflow/DR_model.h5',\n",
    "#     overwrite=True,\n",
    "#     include_optimizer=True,\n",
    "#     save_format=None,\n",
    "#     signatures=None,\n",
    "#     options=None,\n",
    "#     save_traces=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb7a9db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e84436e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('/workspace/DP/Tensorflow/Saved_models/DR_model.h5', custom_objects={\"precision_m\": precision_m, \"f1_m\":f1_m})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a60dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with keras.utils.custom_object_scope(custom_objects):\n",
    "#     new_model = keras.models.clone_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48b75ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('/workspace/DP/Tensorflow/Saved_models/DR_model.h5')\n",
    "# model=keras.models.load_model('/workspace/DP/Tensorflow/Saved_models/DR_model.h5')\n",
    "# model\n",
    "\n",
    "img = Image.open(\"/workspace/DP/Tensorflow/tf_comp_dp/Opencv_augmented_modified/4/0_f_r_-1_16ce555748d8.png\")\n",
    "img = img.resize((224,224))\n",
    "img = np.array(img)\n",
    "img = img/255.0\n",
    "img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c5113ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 970ms/step\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(img)\n",
    "pred = np.argmax(pred)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89720517",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3920391320.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [41], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    http://localhost:8886/view/Tensorflow/tf_comp_dp/Opencv_augmented_modified/3/0_f_r_-1_042470a92154.png\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "http://localhost:8886/view/Tensorflow/tf_comp_dp/Opencv_augmented_modified/3/0_f_r_-1_042470a92154.png\n",
    "        http://localhost:8886/view/Tensorflow/tf_comp_dp/Opencv_augmented_modified/4/0_f_r_-1_10fca1abf338.png\n",
    "                http://localhost:8886/view/Tensorflow/tf_comp_dp/Opencv_augmented_modified/0/f_r_-1002c21358ce6.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ecbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
